{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOM4HJP/lijJ6yn+5JYjhBF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/coldbilberry/repo-gui/blob/main/%D0%A3%D1%80%D0%BE%D0%BA_1_%D0%9E%D1%81%D0%BD%D0%BE%D0%B2%D1%8B_%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D1%8F_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D1%8B%D1%85_%D1%81%D0%B5%D1%82%D0%B5%D0%B9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ss3GpGaAeY0g"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('13_1_files/13_1_Iris.csv')"
      ],
      "metadata": {
        "id": "VztvtLvMenYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "id": "Hwr_a3Dyergg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = df[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']]"
      ],
      "metadata": {
        "id": "l3B-LWR-eu_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "id": "KrYxVqYqewY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "bF_mOVCNeyEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "# sklearn здесь только, чтобы разделить выборку на тренировочную и тестовую\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "JtA3ai8Fe1ke"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Шаг 1. Определение функций, которые понадобяться для обучения\n",
        "# преобразование массива в бинарный вид результатов\n",
        "def to_one_hot(Y):\n",
        "    n_col = np.amax(Y) + 1\n",
        "    binarized = np.zeros((len(Y), n_col))\n",
        "    for i in range(len(Y)):\n",
        "        binarized[i, Y[i]] = 1.\n",
        "    return binarized\n",
        "\n",
        "# преобразование массива в необходимый вид\n",
        "def from_one_hot(Y):\n",
        "    arr = np.zeros((len(Y), 1))\n",
        "\n",
        "    for i in range(len(Y)):\n",
        "        l = layer2[i]\n",
        "        for j in range(len(l)):\n",
        "            if(l[j] == 1):\n",
        "                arr[i] = j+1\n",
        "    return arr\n",
        "\n",
        "# сигмоида и ее производная\n",
        "def sigmoid(x):\n",
        "    return 1/(1+np.exp(-x))\n",
        "\n",
        "def sigmoid_deriv(x):\n",
        "    return sigmoid(x)*(1 - sigmoid(x))\n",
        "\n",
        "# нормализация массива\n",
        "def normalize(X, axis=-1, order=2):\n",
        "    l2 = np.atleast_1d(np.linalg.norm(X, order, axis))\n",
        "    l2[l2 == 0] = 1\n",
        "    return X / np.expand_dims(l2, axis)"
      ],
      "metadata": {
        "id": "Dj4VzQoofZ1o"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Шаг 2. Подготовка тренировочных данных\n",
        "# получения данных из csv файла. укажите здесь путь к файлу Iris.csv\n",
        "iris_data = pd.read_csv(\"13_1_Iris.csv\")\n",
        "\n",
        "# репрезентация данных в виде графиков\n",
        "g = sns.pairplot(iris_data.drop(\"Id\", axis=1), hue=\"Species\")\n",
        "\n",
        "# замена текстовых значений на цифровые\n",
        "iris_data['Species'].replace(['Iris-setosa', 'Iris-virginica', 'Iris-versicolor'], [0, 1, 2], inplace=True)\n",
        "\n",
        "# формирование входных данных\n",
        "columns = ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']\n",
        "x = pd.DataFrame(iris_data, columns=columns)\n",
        "x = normalize(x.to_numpy())\n",
        "\n",
        "# формирование выходных данных(результатов)\n",
        "columns = ['Species']\n",
        "y = pd.DataFrame(iris_data, columns=columns)\n",
        "y = y.to_numpy()\n",
        "y = y.flatten()\n",
        "y = to_one_hot(y)\n",
        "\n",
        "# Разделение данных на тренировочные и тестовые\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
        ""
      ],
      "metadata": {
        "id": "07nvmRQNfekR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "id": "I_nQ4pt7fiOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, multilabel_confusion_matrix"
      ],
      "metadata": {
        "id": "Uqs71_7RflAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 2 слоя\n",
        "### Шаг 3. Обученние нейронной сети\n",
        "# присваивание случайных весов\n",
        "w0 = 2*np.random.random((4, 2)) - 1 # для входного слоя   - 4 входа, 2 выхода\n",
        "w1 = 2*np.random.random((2, 3)) - 1 # для внутреннего слоя - 2 входа, 3 выхода\n",
        "\n",
        "# скорость обучения (learning rate)\n",
        "n = 0.1\n",
        "\n",
        "# массив для ошибок, чтобы потом построить график\n",
        "errors = []\n",
        "\n",
        "# процесс обучения\n",
        "for i in range(100000):\n",
        "\n",
        "    # прямое распространение(feed forward)\n",
        "    layer0 = X_train\n",
        "    layer1 = sigmoid(np.dot(layer0, w0))\n",
        "    layer2 = sigmoid(np.dot(layer1, w1))\n",
        "\n",
        "    # обратное распространение(back propagation) с использованием градиентного спуска\n",
        "    layer2_error = y_train - layer2\n",
        "    layer2_delta = layer2_error * sigmoid_deriv(np.dot(layer1, w1))\n",
        "\n",
        "    layer1_error = layer2_delta.dot(w1.T)\n",
        "    layer1_delta = layer1_error * sigmoid_deriv(np.dot(layer0, w0))\n",
        "\n",
        "    w1 += layer1.T.dot(layer2_delta) * n\n",
        "    w0 += layer0.T.dot(layer1_delta) * n\n",
        "\n",
        "    error = np.mean(np.abs(layer2_error))\n",
        "    errors.append(error)\n",
        "    accuracy = (1 - error) * 100\n",
        "\n",
        "\n",
        "### Шаг 4. Демонстрация полученных результатов\n",
        "# черчение диаграммы точности в зависимости от обучения\n",
        "plt.plot(errors)\n",
        "plt.xlabel('Обучение')\n",
        "plt.ylabel('Ошибка')\n",
        "print(\"Точность нейронной сети \" + str(round(accuracy,2)) + \"%\")\n",
        "\n",
        "print(\"Величина ошибки:\")\n",
        "print(errors[-1])\n",
        "\n",
        "layer1 = sigmoid(np.dot(X_test, w0))\n",
        "pred = sigmoid(np.dot(layer1, w1))\n",
        "print()\n",
        "print(\"Classification report:\")\n",
        "print()\n",
        "print(classification_report(y_test.argmax(-1), pred.argmax(-1)))\n",
        "print(\"Multilabel confusion matrix:\")\n",
        "print()\n",
        "print(multilabel_confusion_matrix(y_test.argmax(-1), pred.argmax(-1)))"
      ],
      "metadata": {
        "id": "hFmKW13rfmLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 3 слоя\n",
        "### Шаг 3. Обученние нейронной сети\n",
        "# присваивание случайных весов\n",
        "w0 = 2*np.random.random((4, 3)) - 1 # для входного слоя   - 4 входа, 3 выхода\n",
        "w1 = 2*np.random.random((3, 3)) - 1 # для внутреннего слоя - 3 входа, 3 выхода\n",
        "\n",
        "# скорость обучения (learning rate)\n",
        "n = 0.1\n",
        "\n",
        "# массив для ошибок, чтобы потом построить график\n",
        "errors = []\n",
        "\n",
        "# процесс обучения\n",
        "for i in range(100000):\n",
        "\n",
        "    # прямое распространение(feed forward)\n",
        "    layer0 = X_train\n",
        "    layer1 = sigmoid(np.dot(layer0, w0))\n",
        "    layer2 = sigmoid(np.dot(layer1, w1))\n",
        "\n",
        "    # обратное распространение(back propagation) с использованием градиентного спуска\n",
        "    layer2_error = y_train - layer2\n",
        "    layer2_delta = layer2_error * sigmoid_deriv(np.dot(layer1, w1))\n",
        "\n",
        "    layer1_error = layer2_delta.dot(w1.T)\n",
        "    layer1_delta = layer1_error * sigmoid_deriv(np.dot(layer0, w0))\n",
        "\n",
        "    w1 += layer1.T.dot(layer2_delta) * n\n",
        "    w0 += layer0.T.dot(layer1_delta) * n\n",
        "\n",
        "    error = np.mean(np.abs(layer2_error))\n",
        "    errors.append(error)\n",
        "    accuracy = (1 - error) * 100\n",
        "\n",
        "\n",
        "### Шаг 4. Демонстрация полученных результатов\n",
        "# черчение диаграммы точности в зависимости от обучения\n",
        "plt.plot(errors)\n",
        "plt.xlabel('Обучение')\n",
        "plt.ylabel('Ошибка')\n",
        "print(\"Точность нейронной сети \" + str(round(accuracy,2)) + \"%\")\n",
        "\n",
        "print(\"Величина ошибки:\")\n",
        "print(errors[-1])\n",
        "\n",
        "layer1 = sigmoid(np.dot(X_test, w0))\n",
        "pred = sigmoid(np.dot(layer1, w1))\n",
        "print()\n",
        "print(\"Classification report:\")\n",
        "print()\n",
        "print(classification_report(y_test.argmax(-1), pred.argmax(-1)))\n",
        "print(\"Multilabel confusion matrix:\")\n",
        "print()\n",
        "print(multilabel_confusion_matrix(y_test.argmax(-1), pred.argmax(-1)))"
      ],
      "metadata": {
        "id": "xA8Wp4vQfrlf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 5 слоёв\n",
        "### Шаг 3. Обученние нейронной сети\n",
        "# присваивание случайных весов\n",
        "w0 = 2*np.random.random((4, 5)) - 1 # для входного слоя   - 4 входа, 5 выходов\n",
        "w1 = 2*np.random.random((5, 3)) - 1 # для внутреннего слоя - 5 входов, 3 выхода\n",
        "\n",
        "# скорость обучения (learning rate)\n",
        "n = 0.1\n",
        "\n",
        "# массив для ошибок, чтобы потом построить график\n",
        "errors = []\n",
        "\n",
        "# процесс обучения\n",
        "for i in range(100000):\n",
        "\n",
        "    # прямое распространение(feed forward)\n",
        "    layer0 = X_train\n",
        "    layer1 = sigmoid(np.dot(layer0, w0))\n",
        "    layer2 = sigmoid(np.dot(layer1, w1))\n",
        "\n",
        "    # обратное распространение(back propagation) с использованием градиентного спуска\n",
        "    layer2_error = y_train - layer2\n",
        "    layer2_delta = layer2_error * sigmoid_deriv(np.dot(layer1, w1))\n",
        "\n",
        "    layer1_error = layer2_delta.dot(w1.T)\n",
        "    layer1_delta = layer1_error * sigmoid_deriv(np.dot(layer0, w0))\n",
        "\n",
        "    w1 += layer1.T.dot(layer2_delta) * n\n",
        "    w0 += layer0.T.dot(layer1_delta) * n\n",
        "\n",
        "    error = np.mean(np.abs(layer2_error))\n",
        "    errors.append(error)\n",
        "    accuracy = (1 - error) * 100\n",
        "\n",
        "\n",
        "### Шаг 4. Демонстрация полученных результатов\n",
        "# черчение диаграммы точности в зависимости от обучения\n",
        "plt.plot(errors)\n",
        "plt.xlabel('Обучение')\n",
        "plt.ylabel('Ошибка')\n",
        "print(\"Точность нейронной сети \" + str(round(accuracy,2)) + \"%\")\n",
        "\n",
        "print(\"Величина ошибки:\")\n",
        "print(errors[-1])\n",
        "\n",
        "layer1 = sigmoid(np.dot(X_test, w0))\n",
        "pred = sigmoid(np.dot(layer1, w1))\n",
        "print()\n",
        "print(\"Classification report:\")\n",
        "print()\n",
        "print(classification_report(y_test.argmax(-1), pred.argmax(-1)))\n",
        "print(\"Multilabel confusion matrix:\")\n",
        "print()\n",
        "print(multilabel_confusion_matrix(y_test.argmax(-1), pred.argmax(-1)))"
      ],
      "metadata": {
        "id": "uAGUjzVufznZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 7 слоёв\n",
        "### Шаг 3. Обученние нейронной сети\n",
        "# присваивание случайных весов\n",
        "w0 = 2*np.random.random((4, 7)) - 1 # для входного слоя   - 4 входа, 7 выходов\n",
        "w1 = 2*np.random.random((7, 3)) - 1 # для внутреннего слоя - 7 входов, 3 выхода\n",
        "\n",
        "# скорость обучения (learning rate)\n",
        "n = 0.1\n",
        "\n",
        "# массив для ошибок, чтобы потом построить график\n",
        "errors = []\n",
        "\n",
        "# процесс обучения\n",
        "for i in range(100000):\n",
        "\n",
        "    # прямое распространение(feed forward)\n",
        "    layer0 = X_train\n",
        "    layer1 = sigmoid(np.dot(layer0, w0))\n",
        "    layer2 = sigmoid(np.dot(layer1, w1))\n",
        "\n",
        "    # обратное распространение(back propagation) с использованием градиентного спуска\n",
        "    layer2_error = y_train - layer2\n",
        "    layer2_delta = layer2_error * sigmoid_deriv(np.dot(layer1, w1))\n",
        "\n",
        "    layer1_error = layer2_delta.dot(w1.T)\n",
        "    layer1_delta = layer1_error * sigmoid_deriv(np.dot(layer0, w0))\n",
        "\n",
        "    w1 += layer1.T.dot(layer2_delta) * n\n",
        "    w0 += layer0.T.dot(layer1_delta) * n\n",
        "\n",
        "    error = np.mean(np.abs(layer2_error))\n",
        "    errors.append(error)\n",
        "    accuracy = (1 - error) * 100\n",
        "\n",
        "\n",
        "### Шаг 4. Демонстрация полученных результатов\n",
        "# черчение диаграммы точности в зависимости от обучения\n",
        "plt.plot(errors)\n",
        "plt.xlabel('Обучение')\n",
        "plt.ylabel('Ошибка')\n",
        "print(\"Точность нейронной сети \" + str(round(accuracy,2)) + \"%\")\n",
        "\n",
        "print(\"Величина ошибки:\")\n",
        "print(errors[-1])\n",
        "\n",
        "layer1 = sigmoid(np.dot(X_test, w0))\n",
        "pred = sigmoid(np.dot(layer1, w1))\n",
        "print()\n",
        "print(\"Classification report:\")\n",
        "print()\n",
        "print(classification_report(y_test.argmax(-1), pred.argmax(-1)))\n",
        "print(\"Multilabel confusion matrix:\")\n",
        "print()\n",
        "print(multilabel_confusion_matrix(y_test.argmax(-1), pred.argmax(-1)))"
      ],
      "metadata": {
        "id": "P8WXzWRXf9O1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 7 слоёв\n",
        "### Шаг 3. Обученние нейронной сети\n",
        "# присваивание случайных весов\n",
        "w0 = 2*np.random.random((4, 7)) - 1 # для входного слоя   - 4 входа, 7 выходов\n",
        "w1 = 2*np.random.random((7, 3)) - 1 # для внутреннего слоя - 7 входов, 3 выхода\n",
        "\n",
        "# скорость обучения (learning rate)\n",
        "n = 0.01\n",
        "\n",
        "# массив для ошибок, чтобы потом построить график\n",
        "errors = []\n",
        "\n",
        "# процесс обучения\n",
        "for i in range(100000):\n",
        "\n",
        "    # прямое распространение(feed forward)\n",
        "    layer0 = X_train\n",
        "    layer1 = sigmoid(np.dot(layer0, w0))\n",
        "    layer2 = sigmoid(np.dot(layer1, w1))\n",
        "\n",
        "    # обратное распространение(back propagation) с использованием градиентного спуска\n",
        "    layer2_error = y_train - layer2\n",
        "    layer2_delta = layer2_error * sigmoid_deriv(np.dot(layer1, w1))\n",
        "\n",
        "    layer1_error = layer2_delta.dot(w1.T)\n",
        "    layer1_delta = layer1_error * sigmoid_deriv(np.dot(layer0, w0))\n",
        "\n",
        "    w1 += layer1.T.dot(layer2_delta) * n\n",
        "    w0 += layer0.T.dot(layer1_delta) * n\n",
        "\n",
        "    error = np.mean(np.abs(layer2_error))\n",
        "    errors.append(error)\n",
        "    accuracy = (1 - error) * 100\n",
        "\n",
        "\n",
        "### Шаг 4. Демонстрация полученных результатов\n",
        "# черчение диаграммы точности в зависимости от обучения\n",
        "plt.plot(errors)\n",
        "plt.xlabel('Обучение')\n",
        "plt.ylabel('Ошибка')\n",
        "print(\"Точность нейронной сети \" + str(round(accuracy,2)) + \"%\")\n",
        "\n",
        "print(\"Величина ошибки:\")\n",
        "print(errors[-1])\n",
        "\n",
        "layer1 = sigmoid(np.dot(X_test, w0))\n",
        "pred = sigmoid(np.dot(layer1, w1))\n",
        "print()\n",
        "print(\"Classification report:\")\n",
        "print()\n",
        "print(classification_report(y_test.argmax(-1), pred.argmax(-1)))\n",
        "print(\"Multilabel confusion matrix:\")\n",
        "print()\n",
        "print(multilabel_confusion_matrix(y_test.argmax(-1), pred.argmax(-1)))"
      ],
      "metadata": {
        "id": "bUtmnoVHgA9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выводы:\n",
        "\n",
        "На точность представленной нейронной сети влияет:\n",
        "\n",
        "количество внутренних слоев - недостаточное или наоборот избыточное количество слоёв увеличивает ошибку\n",
        "скорость обучения - неправильно подобранная скорость обучения не позволяет достичь лучшего результата"
      ],
      "metadata": {
        "id": "lvbLq0QSgHnL"
      }
    }
  ]
}